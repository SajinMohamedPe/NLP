{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Student ID : 23037601  \n",
        "Student Name : Sajin Mohamed Pallikkathodi Erathali"
      ],
      "metadata": {
        "id": "8djTKPese1Sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "S6yhPTaLVJRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$P(w_{i}|w_{i-1}) = \\frac{c(w_{i-1}, w_{i})} {c(w_{i-1})} $$\n"
      ],
      "metadata": {
        "id": "06Xb6q7O0LXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://norvig.com/ngrams/count_1w.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOi3NAk4CPqg",
        "outputId": "3f5009d0-2d84-4d25-8496-7bcffe52e289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-30 07:30:26--  https://norvig.com/ngrams/count_1w.txt\n",
            "Resolving norvig.com (norvig.com)... 158.106.138.13\n",
            "Connecting to norvig.com (norvig.com)|158.106.138.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4956241 (4.7M) [text/plain]\n",
            "Saving to: ‘count_1w.txt.1’\n",
            "\n",
            "count_1w.txt.1      100%[===================>]   4.73M  29.1MB/s    in 0.2s    \n",
            "\n",
            "2023-10-30 07:30:26 (29.1 MB/s) - ‘count_1w.txt.1’ saved [4956241/4956241]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://norvig.com/ngrams/count_2w.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0AFz7tNCben",
        "outputId": "92f7dd89-8db0-4f79-8af9-8041e9ac8014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-30 07:30:26--  https://norvig.com/ngrams/count_2w.txt\n",
            "Resolving norvig.com (norvig.com)... 158.106.138.13\n",
            "Connecting to norvig.com (norvig.com)|158.106.138.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5566017 (5.3M) [text/plain]\n",
            "Saving to: ‘count_2w.txt.1’\n",
            "\n",
            "count_2w.txt.1      100%[===================>]   5.31M  29.3MB/s    in 0.2s    \n",
            "\n",
            "2023-10-30 07:30:27 (29.3 MB/s) - ‘count_2w.txt.1’ saved [5566017/5566017]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unigrams_df = pd.read_csv('count_1w.txt', header=None, delimiter = '\\t', names = ['word', 'count'])\n",
        "bigrams_df = pd.read_csv('count_2w.txt', header=None, delimiter = '\\t', names = ['word', 'count'])\n",
        "\n",
        "# total count of unigrams is the unigrams.shape\n",
        "totalUnigrams = unigrams_df.shape[0];\n",
        "totalBigrams = bigrams_df.shape[0];\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f'Number of unigrams:{totalUnigrams} Number of Bigrams: {totalBigrams}')\n",
        "print(unigrams_df.head(100),bigrams_df.head(100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFo4a_XvCnXl",
        "outputId": "948f5112-6139-4e3b-fade-8700fecd023e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unigrams:333333 Number of Bigrams: 286358\n",
            "       word        count\n",
            "0       the  23135851162\n",
            "1        of  13151942776\n",
            "2       and  12997637966\n",
            "3        to  12136980858\n",
            "4         a   9081174698\n",
            "..      ...          ...\n",
            "95     like    520585287\n",
            "96  service    519537222\n",
            "97        x    508609523\n",
            "98     than    502609275\n",
            "99     find    502043038\n",
            "\n",
            "[100 rows x 2 columns]                  word   count\n",
            "0    0Uplink verified  523545\n",
            "1              0km to  116103\n",
            "2            1000s of  939476\n",
            "3             100s of  539389\n",
            "4   100th anniversary  158621\n",
            "..                ...     ...\n",
            "95            24th of  327460\n",
            "96   25th anniversary  261023\n",
            "97            25th of  397735\n",
            "98            26th of  271707\n",
            "99            27th of  276619\n",
            "\n",
            "[100 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a generic method to get and display the count of unigram and bigram\n",
        "def find_count_value(dataFrame, words, identifier) :\n",
        "\n",
        "  # filter out dataframe that has the unigram to then select the count\n",
        "      wordExistDf = dataFrame[dataFrame['word'] == words]\n",
        "\n",
        "      if not wordExistDf.empty:\n",
        "        # Retrieve the 'count' value from the filtered DataFrame\n",
        "        dataFrame_count_value = wordExistDf['count'].iloc[0]\n",
        "        print(f'{identifier} count for {words} = {dataFrame_count_value}')\n",
        "      return dataFrame_count_value"
      ],
      "metadata": {
        "id": "ahpjwVejjOW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def probability(sentence):\n",
        "    words = str.split(sentence, \" \")\n",
        "    print(\"sentence = \", words)\n",
        "    sentence_probability = 1.0\n",
        "\n",
        "    for i in range(len(words)-1):\n",
        "\n",
        "      unigram = words[i]\n",
        "      unigram_count_value = find_count_value(unigrams_df, unigram, \"unigram\")\n",
        "\n",
        "      bigram = words[i] + ' ' + words[i+1]\n",
        "      bigram_count_value = find_count_value(bigrams_df, bigram, \"bigram\")\n",
        "\n",
        "\n",
        "      bigram_prob = bigram_count_value/unigram_count_value if unigram_count_value != 0 else 0\n",
        "\n",
        "      print(f'bigram probability of {bigram} = ',  bigram_prob, \"\\n\")\n",
        "      print(\"---------------------------------------------------------------\")\n",
        "\n",
        "      sentence_probability *= bigram_prob\n",
        "\n",
        "    print(f\"sentence probability for {sentence} = \", sentence_probability, \"\\n\")\n",
        "    return sentence_probability\n",
        "\n",
        "probability(\"i love you\") > probability('i hate you')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFpGFGyYHNPh",
        "outputId": "1a769562-670b-422c-c25a-8e3584fd2bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence =  ['i', 'love', 'you']\n",
            "unigram count for i = 3086225277\n",
            "bigram count for i love = 3979312\n",
            "bigram probability of i love =  0.001289378332053626 \n",
            "\n",
            "---------------------------------------------------------------\n",
            "unigram count for love = 201063526\n",
            "bigram count for love you = 5428714\n",
            "bigram probability of love you =  0.02699999402178991 \n",
            "\n",
            "---------------------------------------------------------------\n",
            "sentence probability for i love you =  3.481320725727335e-05 \n",
            "\n",
            "sentence =  ['i', 'hate', 'you']\n",
            "unigram count for i = 3086225277\n",
            "bigram count for i hate = 876611\n",
            "bigram probability of i hate =  0.0002840398614232463 \n",
            "\n",
            "---------------------------------------------------------------\n",
            "unigram count for hate = 21274675\n",
            "bigram count for hate you = 504048\n",
            "bigram probability of hate you =  0.023692394830943365 \n",
            "\n",
            "---------------------------------------------------------------\n",
            "sentence probability for i hate you =  6.7295845445659906e-06 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "def probability_with_add_one_smoothing(sentence):\n",
        "    words = str.split(sentence, \" \")\n",
        "    print(\"sentence = \", words)\n",
        "    vocabulary = len(unigrams_df)\n",
        "    sentence_probability = 0.0\n",
        "\n",
        "    for i in range(len(words)-1):\n",
        "\n",
        "      unigram = words[i]\n",
        "      unigram_count_value = find_count_value(unigrams_df, unigram, \"unigram\")\n",
        "\n",
        "      bigram = words[i] + ' ' + words[i+1]\n",
        "      bigram_count_value = find_count_value(bigrams_df, bigram, \"bigram\")\n",
        "\n",
        "      # note the addition of vocabulary and 1 and the inclusion of log to remove the multiplication of very small values and marking them zero, instead we take the log and sum them up\n",
        "      bigram_prob = math.log((bigram_count_value+1)/(unigram_count_value + vocabulary))\n",
        "\n",
        "      print(f'bigram probability of {bigram} = ',  bigram_prob, \"\\n\")\n",
        "      print(\"---------------------------------------------------------------\")\n",
        "\n",
        "      sentence_probability += bigram_prob\n",
        "\n",
        "    print(f\"sentence probability for {sentence} = \", sentence_probability, \"\\n\")\n",
        "    return sentence_probability\n",
        "\n",
        "probability_with_add_one_smoothing(\"i love you\") > probability_with_add_one_smoothing('i hate you')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihn37I8Mrkcc",
        "outputId": "caaeb6b3-9d13-4291-f034-65188e7ae80c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence =  ['i', 'love', 'you']\n",
            "unigram count for i = 3086225277\n",
            "bigram count for i love = 3979312\n",
            "bigram probability of i love =  -6.653702839468271 \n",
            "\n",
            "---------------------------------------------------------------\n",
            "unigram count for love = 201063526\n",
            "bigram count for love you = 5428714\n",
            "bigram probability of love you =  -3.613574926643882 \n",
            "\n",
            "---------------------------------------------------------------\n",
            "sentence probability for i love you =  -10.267277766112153 \n",
            "\n",
            "sentence =  ['i', 'hate', 'you']\n",
            "unigram count for i = 3086225277\n",
            "bigram count for i hate = 876611\n",
            "bigram probability of i hate =  -8.16650283263713 \n",
            "\n",
            "---------------------------------------------------------------\n",
            "unigram count for hate = 21274675\n",
            "bigram count for hate you = 504048\n",
            "bigram probability of hate you =  -3.758145780137813 \n",
            "\n",
            "---------------------------------------------------------------\n",
            "sentence probability for i hate you =  -11.924648612774943 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "START_SYMBOL = '<S>'\n",
        "\n",
        "# method to find the set of words that start with the given word in the bigram\n",
        "def bigrams_start_with(word):\n",
        "    result_list = [x.startswith(word) for x in bigrams_df['word']]\n",
        "    return bigrams_df[result_list]\n",
        "\n",
        "# method to find the set of words that end with the given word in the bigram\n",
        "def bigrams_end_with(word):\n",
        "    result_list = [x.endswith(word) for x in bigrams_df['word']]\n",
        "    return bigrams_df[result_list]\n",
        "\n",
        "\n",
        "def choose_according_to_probability(df):\n",
        "    df = df.copy() # added due to warnings\n",
        "    total = df['count'].sum()\n",
        "    df['probability'] = df['count']/total # adding a new column to the dataframe inorder to fit them into a probability line(0-1)\n",
        "    df['cumulative_probability'] = df['probability'].cumsum()\n",
        "    random_number = random.random()\n",
        "    chosen_bigram = df[df['cumulative_probability'] >= random_number].iloc[0]\n",
        "    chosen_bigram = chosen_bigram.drop(['probability', 'cumulative_probability'])\n",
        "    return chosen_bigram"
      ],
      "metadata": {
        "id": "xL7NeE_sZBLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An Alternative solution using recursion"
      ],
      "metadata": {
        "id": "UBIwABrUcyPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def shannon_visualization(end_word = None):\n",
        "#     # Keep track of all the words\n",
        "#     final_sentence = \"\"\n",
        "\n",
        "#     # Recursive inner function\n",
        "#     def shannon_visualization_inner(prev_word, word, padding):\n",
        "#         nonlocal final_sentence\n",
        "\n",
        "#         # Add current word to sentence\n",
        "#         final_sentence += \" \" + word\n",
        "\n",
        "#         # Print this step with the padding\n",
        "#         print(f\"{' '*padding}{prev_word} {word}\")\n",
        "\n",
        "#         # If the final word is reached, return\n",
        "#         if word == end_word:\n",
        "#             return\n",
        "\n",
        "#         # Find next words starting the current word inorder to determine the probability later\n",
        "#         next_bigrams = bigrams_start_with(word)\n",
        "\n",
        "#         # No bigrams starting with \"word\"\n",
        "#         if len(next_bigrams) == 0:\n",
        "#             final_sentence += \".\"\n",
        "#             return\n",
        "\n",
        "#         # Find next word according to count\n",
        "#         next_bigram = choose_according_to_probability(next_bigrams)\n",
        "\n",
        "#         # Get word from bigram\n",
        "#         next_word = next_bigram[\"word\"].split()[1]\n",
        "\n",
        "#         # Recur to next word pair\n",
        "#         shannon_visualization_inner(word, next_word, padding+1+len(prev_word))\n",
        "#         return # Function end\n",
        "\n",
        "#     # Start recursion by finding the next word after the starting symbol\n",
        "#     next_word = choose_according_to_probability(bigrams_start_with(START_SYMBOL))[\"word\"].split()[1]\n",
        "#     shannon_visualization_inner(START_SYMBOL, next_word, 0)\n",
        "\n",
        "#     # Remove extra space\n",
        "#     return final_sentence[1:]"
      ],
      "metadata": {
        "id": "zGNJhkIrZCG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A simpler approach"
      ],
      "metadata": {
        "id": "G8w0K4RLeekG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shannon_visualization(end_word=None):\n",
        "    shannon_words = []\n",
        "    shannon_words.append(START_SYMBOL)\n",
        "\n",
        "\n",
        "    # Iterate indefinitely until the end word is found or there are no more bigrams\n",
        "    while True:\n",
        "        current_word = shannon_words[-1]\n",
        "        # Find the next word\n",
        "        next_bigrams = bigrams_start_with(current_word)\n",
        "        # No bigrams starting with \"word\" or if the current word matches the end word\n",
        "        if (len(next_bigrams) == 0) | (current_word == end_word):\n",
        "            break\n",
        "        next_bigram = choose_according_to_probability(next_bigrams)\n",
        "        next_word = next_bigram[\"word\"].split()[1]\n",
        "        shannon_words.append(next_word)\n",
        "        print(\"bigram\" , shannon_words)\n",
        "\n",
        "    # Join words into a sentence (without the starting symbol)\n",
        "    final_sentence = \" \".join(shannon_words[1:])\n",
        "\n",
        "    return final_sentence"
      ],
      "metadata": {
        "id": "DuJ6iJolbuFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(10)\n",
        "# No end word, terminates automatically\n",
        "sentence = shannon_visualization()\n",
        "print(f\"Final Sentence: {sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0IqSq5KZElC",
        "outputId": "8f2215e4-7425-41ac-e84f-dbf58e9cde37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigram ['<S>', 'no']\n",
            "bigram ['<S>', 'no', 'get']\n",
            "bigram ['<S>', 'no', 'get', 'the']\n",
            "bigram ['<S>', 'no', 'get', 'the', 'early']\n",
            "bigram ['<S>', 'no', 'get', 'the', 'early', 'stages']\n",
            "bigram ['<S>', 'no', 'get', 'the', 'early', 'stages', 'of']\n",
            "bigram ['<S>', 'no', 'get', 'the', 'early', 'stages', 'of', 'the']\n",
            "bigram ['<S>', 'no', 'get', 'the', 'early', 'stages', 'of', 'the', 'crown']\n",
            "bigram ['<S>', 'no', 'get', 'the', 'early', 'stages', 'of', 'the', 'crown', 'of']\n",
            "bigram ['<S>', 'no', 'get', 'the', 'early', 'stages', 'of', 'the', 'crown', 'of', 'mitochondrial']\n",
            "Final Sentence: no get the early stages of the crown of mitochondrial\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(56)\n",
        "# Terminates when \"cute\" is found\n",
        "sentence = shannon_visualization(\"that\")\n",
        "print(f\"Final Sentence: {sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSLlUK0hZlWi",
        "outputId": "b7da99bd-3948-4017-fee3-b354088f8d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigram ['<S>', 'why']\n",
            "bigram ['<S>', 'why', 'some']\n",
            "bigram ['<S>', 'why', 'some', 'point']\n",
            "bigram ['<S>', 'why', 'some', 'point', 'to']\n",
            "bigram ['<S>', 'why', 'some', 'point', 'to', 'the']\n",
            "bigram ['<S>', 'why', 'some', 'point', 'to', 'the', 'probably']\n",
            "bigram ['<S>', 'why', 'some', 'point', 'to', 'the', 'probably', 'have']\n",
            "bigram ['<S>', 'why', 'some', 'point', 'to', 'the', 'probably', 'have', 'been']\n",
            "bigram ['<S>', 'why', 'some', 'point', 'to', 'the', 'probably', 'have', 'been', 'found']\n",
            "bigram ['<S>', 'why', 'some', 'point', 'to', 'the', 'probably', 'have', 'been', 'found', 'at']\n",
            "bigram ['<S>', 'why', 'some', 'point', 'to', 'the', 'probably', 'have', 'been', 'found', 'at', 'the']\n",
            "bigram ['<S>', 'why', 'some', 'point', 'to', 'the', 'probably', 'have', 'been', 'found', 'at', 'the', 'think']\n",
            "bigram ['<S>', 'why', 'some', 'point', 'to', 'the', 'probably', 'have', 'been', 'found', 'at', 'the', 'think', 'it']\n",
            "bigram ['<S>', 'why', 'some', 'point', 'to', 'the', 'probably', 'have', 'been', 'found', 'at', 'the', 'think', 'it', 'of']\n",
            "bigram ['<S>', 'why', 'some', 'point', 'to', 'the', 'probably', 'have', 'been', 'found', 'at', 'the', 'think', 'it', 'of', 'forces']\n",
            "bigram ['<S>', 'why', 'some', 'point', 'to', 'the', 'probably', 'have', 'been', 'found', 'at', 'the', 'think', 'it', 'of', 'forces', 'with']\n",
            "bigram ['<S>', 'why', 'some', 'point', 'to', 'the', 'probably', 'have', 'been', 'found', 'at', 'the', 'think', 'it', 'of', 'forces', 'with', 'that']\n",
            "Final Sentence: why some point to the probably have been found at the think it of forces with that\n"
          ]
        }
      ]
    }
  ]
}