{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsWu7dFPxyI3"
      },
      "source": [
        "Student Name : Sajin Mohamed Pallikkathodi Erathali  \n",
        "Student ID : 23037601"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH1c5qbOcLTh"
      },
      "source": [
        "\n",
        "$$PrecisionclassFood = \\frac{TP} {TP + FP} = \\frac{800} {800 + 200} = .8$$\n",
        "\n",
        "$$PrecisionclassFood = \\frac{TP} {TP + FN} = \\frac{800} {800 + 200} = .8$$\n",
        "\n",
        "$$PrecisionclassDrink = \\frac{TP} {TP + FP} = \\frac{70} {70 + 30} = .7$$\n",
        "\n",
        "$$RecallclassDrink = \\frac{TP} {TP + FN} = \\frac{70} {70 + 30} = .7$$\n",
        "\n",
        "\n",
        "$$PrecisionMacroAverage = \\frac{\\frac{TPmacro} {TPmacro + FPmacro}}{N}  = \\frac{\\frac{800} {800 + 200}  + \\frac{70} {70+30}} 2 = \\frac{.8 + .7}{2} = \\frac{1.5}{2}= .75$$\n",
        "\n",
        "$$RecallMacroAverage = \\frac{\\frac{TP} {TP + FN}} {N} =  \\frac{\\frac{800} {800 + 200} + \\frac{70} {70 + 30}}  {2} = \\frac{1.5} {2} = .75$$\n",
        "\n",
        "\n",
        "$$ F1macro = \\frac{2 Precision*Recall}{Precision + Recall} = \\frac{ 2 X .75 X .75}{.75 + .75} = \\frac{1.125}{1.5}  = 0.75$$\n",
        "\n",
        "$$PrecisionMicroAverage = \\frac{TPmicro} {TPmicro + FPmicro}  = \\frac{(800 + 70)} {(200 + 30 + 800 + 70)}  = \\frac{870}{870 + 230} = \\frac{870}{1100}= .7907$$\n",
        "\n",
        "\n",
        "$$RecallMicroAverage = \\frac{TP} {TP + FN} =  \\frac{800 + 70} {200+30+800+70}  = \\frac{870} {1100}= .79$$\n",
        "\n",
        "\n",
        "$$ F1micro = \\frac{2 Precision*Recall}{Precision + Recall} = \\frac{ 2 X .79 X .79}{.79 + .79} = \\frac{1.24}{1.58}  = 0.784$$\n",
        "\n",
        "\n",
        "The difference in macro f1 and micro f1 is due to the fact that the Macro average F1 score is calculated by using the average f1 score of  all the classes hence it treats all classes equally. Hence, even if we have imbalanced classes it would weigh the classes equally. The contribution is different when calculating the micro average f1 as it takes all the classes to calculate the average metric. Hence weightage would be different for different classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaOfuvjGnQBL",
        "outputId": "2f53b6ec-0ed2-4906-affa-d2da0d1d810d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "string = NLP is cool\n",
            "Sentiment(polarity=0.35, subjectivity=0.65)\n",
            "Positive sentiment ðŸ˜Š\n",
            "subjectivity =  0.65\n",
            "------------------------------------------------------------------------------------------\n",
            "string = NLP is cool and useful\n",
            "Sentiment(polarity=0.32499999999999996, subjectivity=0.325)\n",
            "Positive sentiment ðŸ˜Š\n",
            "subjectivity =  0.325\n",
            "------------------------------------------------------------------------------------------\n",
            "string = NLP is hard\n",
            "Sentiment(polarity=-0.2916666666666667, subjectivity=0.5416666666666666)\n",
            "Negative sentiment ðŸ˜”\n",
            "subjectivity =  0.5416666666666666\n",
            "------------------------------------------------------------------------------------------\n",
            "string = NLP is hard and useless\n",
            "Sentiment(polarity=-0.39583333333333337, subjectivity=0.37083333333333335)\n",
            "Negative sentiment ðŸ˜”\n",
            "subjectivity =  0.37083333333333335\n",
            "------------------------------------------------------------------------------------------\n",
            "string = NLP stands for Natural Language\n",
            "Sentiment(polarity=0.1, subjectivity=0.4)\n",
            "Neutral sentiment ðŸ˜\n",
            "subjectivity =  0.4\n",
            "------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "from textblob import TextBlob\n",
        "\n",
        "def sentimentAnalyzer(string):\n",
        "  testimonial = TextBlob(string)\n",
        "  print(\"string =\" , string)\n",
        "  print(testimonial.sentiment)\n",
        "\n",
        "  if (testimonial.polarity > 0.15):\n",
        "    print(\"Positive sentiment ðŸ˜Š\")\n",
        "  elif (testimonial.polarity < -0.15):\n",
        "    print(\"Negative sentiment ðŸ˜”\")\n",
        "  else:\n",
        "    print(\"Neutral sentiment ðŸ˜\")\n",
        "\n",
        "  print(\"subjectivity = \", testimonial.subjectivity)\n",
        "  print(\"-\"*90)\n",
        "sentimentAnalyzer (\"NLP is cool\")\n",
        "sentimentAnalyzer (\"NLP is cool and useful\")\n",
        "sentimentAnalyzer (\"NLP is hard\")\n",
        "sentimentAnalyzer(\"NLP is hard and useless\")\n",
        "sentimentAnalyzer (\"NLP stands for Natural Language\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz1jwuIMrjJ7",
        "outputId": "7ed53e36-1cca-4bd7-b84f-2f979ac22b3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prior of Positive 0.0\n",
            "prior of Negative 1.0\n",
            "\n",
            "megaDocPositive []\n",
            "megaDocNegative ['just plain boring', 'entirely predictable and lacks energy', 'no surprises and very few laughs', 'very powerful', 'the most fun film of the summer']\n",
            "\n",
            "Positive_BOW =  {}\n",
            "Negative_BOW =  {'just': 1, 'plain': 1, 'boring': 1, 'entirely': 1, 'predictable': 1, 'and': 2, 'lacks': 1, 'energy': 1, 'no': 1, 'surprises': 1, 'very': 2, 'few': 1, 'laughs': 1, 'powerful': 1, 'the': 2, 'most': 1, 'fun': 1, 'film': 1, 'of': 1, 'summer': 1}\n",
            "<class 'dict'>\n",
            "V =  {'just': 1, 'plain': 1, 'boring': 1, 'entirely': 1, 'predictable': 1, 'and': 2, 'lacks': 1, 'energy': 1, 'no': 1, 'surprises': 1, 'very': 2, 'few': 1, 'laughs': 1, 'powerful': 1, 'the': 2, 'most': 1, 'fun': 1, 'film': 1, 'of': 1, 'summer': 1}\n",
            "|V| = 20\n",
            "\n",
            "{}\n",
            "Test Document = (predictable with no fun)\n",
            "word =  predictable\n",
            "wordCondProbabiltyPositive =  0.05\n",
            "wordCondProbabiltyNegative =  0.046511627906976744\n",
            "\n",
            "word =  with\n",
            "wordCondProbabiltyPositive =  0.05\n",
            "wordCondProbabiltyNegative =  0.023255813953488372\n",
            "\n",
            "word =  no\n",
            "wordCondProbabiltyPositive =  0.05\n",
            "wordCondProbabiltyNegative =  0.046511627906976744\n",
            "\n",
            "word =  fun\n",
            "wordCondProbabiltyPositive =  0.05\n",
            "wordCondProbabiltyNegative =  0.046511627906976744\n",
            "\n",
            "DocProbPositive =  0.0\n",
            "DocProbNegative =  0.0\n",
            "Inferred Class : Negative\n",
            "\n",
            "string = predictable with no fun\n",
            "Sentiment(polarity=-0.175, subjectivity=0.35)\n",
            "Negative sentiment ðŸ˜”\n",
            "------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "trainingSet = [('just plain boring','-'),('entirely predictable and lacks energy','-'),('no surprises and very few laughs','-'),('very powerful','+'),('the most fun film of the summer','+')]\n",
        "testSet = [\"predictable with no fun\"]\n",
        "\n",
        "megaDocPositive = []\n",
        "megaDocNegative = []\n",
        "total_count_of_documents_in_train = 0\n",
        "total_count_of_documents_in_Positive = 0\n",
        "total_count_of_documents_in_Negative = 0\n",
        "# get count for calculating the prior and form the megadocument\n",
        "for i in trainingSet:\n",
        "    total_count_of_documents_in_train += 1\n",
        "    if i[1] == 'Positive':\n",
        "        megaDocPositive.append(i[0].lower())\n",
        "        total_count_of_documents_in_Positive += 1\n",
        "\n",
        "    else:\n",
        "        megaDocNegative.append(i[0].lower())\n",
        "        total_count_of_documents_in_Negative += 1\n",
        "\n",
        "priorPositive = total_count_of_documents_in_Positive/total_count_of_documents_in_train\n",
        "priorNegative = total_count_of_documents_in_Negative/total_count_of_documents_in_train\n",
        "\n",
        "print(\"prior of Positive\", priorPositive)\n",
        "print(\"prior of Negative\", priorNegative)\n",
        "print()\n",
        "print(\"megaDocPositive\", megaDocPositive)\n",
        "print(\"megaDocNegative\", megaDocNegative)\n",
        "print()\n",
        "\n",
        "# used for find the bag of words provided the megadocument\n",
        "def find_BOW(megaDoc):\n",
        "    count = {}\n",
        "    words = ' '.join(megaDoc).split()\n",
        "\n",
        "    for i in words:\n",
        "        if i not in count:\n",
        "            count[i] = 1\n",
        "        else:\n",
        "            count[i] += 1\n",
        "    return count\n",
        "\n",
        "Positive_BOW = find_BOW(megaDocPositive)\n",
        "Negative_BOW = find_BOW(megaDocNegative)\n",
        "print(\"Positive_BOW = \", Positive_BOW)\n",
        "print(\"Negative_BOW = \", Negative_BOW)\n",
        "print(type(Positive_BOW))\n",
        "\n",
        "\n",
        "# used to find the vocabulary count\n",
        "listPositive = ' '.join(megaDocPositive).split()\n",
        "listNegative = ' '.join(megaDocNegative).split() + listPositive\n",
        "\n",
        "\n",
        "vocabulary = {}\n",
        "\n",
        "for i in listNegative:\n",
        "    vocabulary[i] = listNegative.count(i)\n",
        "\n",
        "# displaying the vocabulary\n",
        "print(\"V = \", vocabulary)\n",
        "print(f\"|V| = {len(vocabulary)}\")\n",
        "print()\n",
        "\n",
        "count = {}\n",
        "words = ' '.join(find_BOW(megaDocPositive)).split()\n",
        "for i in words:\n",
        "        if i not in count:\n",
        "            count[i] = 1\n",
        "        else:\n",
        "            count[i] += 1\n",
        "\n",
        "print(count)\n",
        "\n",
        "# used for get the count of words\n",
        "def get_map_count_for_each_class(word, BOW):\n",
        "    count = 0\n",
        "    if (word in BOW) :\n",
        "      count += 1\n",
        "\n",
        "    return count\n",
        "\n",
        "\n",
        "\n",
        "def naiveBayesClassifier(trainingSet, testSet) :\n",
        "\n",
        "  for i in testSet :\n",
        "    print(f\"Test Document = ({i})\")\n",
        "    word_cond_prob_Positive = 1\n",
        "    word_cond_prob_Negative = 1\n",
        "    for word in i.split():\n",
        "      lower_word = word.lower()\n",
        "\n",
        "      print(\"word = \", lower_word)\n",
        "      count_of_word_in_Positive = get_map_count_for_each_class(lower_word, Positive_BOW)\n",
        "      count_of_word_in_Negative = get_map_count_for_each_class(lower_word, Negative_BOW)\n",
        "\n",
        "      number_of_words_in_Positive = sum(Positive_BOW.values())\n",
        "      number_of_words_in_Negative = sum(Negative_BOW.values())\n",
        "\n",
        "      print(\"wordCondProbabiltyPositive = \", (count_of_word_in_Positive + 1)/ (number_of_words_in_Positive + (len(vocabulary))))\n",
        "      print(\"wordCondProbabiltyNegative = \", (count_of_word_in_Negative + 1)/ (number_of_words_in_Negative + (len(vocabulary))))\n",
        "      word_cond_prob_Positive = word_cond_prob_Positive * (count_of_word_in_Positive + 1)/ (number_of_words_in_Positive + (len(vocabulary)))\n",
        "      word_cond_prob_Negative = word_cond_prob_Negative * (count_of_word_in_Negative + 1)/ (number_of_words_in_Negative + (len(vocabulary)))\n",
        "\n",
        "      print()\n",
        "\n",
        "    print(\"DocProbPositive = \", round(priorPositive * word_cond_prob_Positive,5))\n",
        "    print(\"DocProbNegative = \", round(priorNegative * word_cond_prob_Negative,5))\n",
        "\n",
        "    if(priorPositive * word_cond_prob_Positive > priorNegative * word_cond_prob_Negative) :\n",
        "        print(\"Inferred Class : Positive\" )\n",
        "    else :\n",
        "        print(\"Inferred Class : Negative\" )\n",
        "    print()\n",
        "    testimonial = TextBlob(testSet[0])\n",
        "    print(\"string =\" , testSet[0])\n",
        "    print(testimonial.sentiment)\n",
        "\n",
        "    if (testimonial.polarity > 0):\n",
        "        print(\"Positive sentiment ðŸ˜Š\")\n",
        "    elif (testimonial.polarity < 0):\n",
        "            print(\"Negative sentiment ðŸ˜”\")\n",
        "    print(\"-\"*90)\n",
        "\n",
        "\n",
        "\n",
        "naiveBayesClassifier(trainingSet, testSet)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
